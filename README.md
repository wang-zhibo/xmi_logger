# XmiLogger

åŸºäº Loguru çš„å¢å¼ºæ—¥å¿—è®°å½•å™¨ï¼Œæ”¯æŒå¤šè¯­è¨€ã€å¼‚æ­¥æ“ä½œå’Œé«˜çº§ç»Ÿè®¡åŠŸèƒ½ã€‚

## ç‰¹æ€§

- ğŸš€ é«˜æ€§èƒ½ï¼šä½¿ç”¨ LRU ç¼“å­˜å’Œå¼‚æ­¥å¤„ç†
- ğŸŒ å¤šè¯­è¨€æ”¯æŒï¼šæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æ—¥å¿—è¾“å‡º
- ğŸ“Š é«˜çº§ç»Ÿè®¡ï¼šæ”¯æŒæ—¥å¿—åˆ†ç±»ç»Ÿè®¡å’Œè¶‹åŠ¿åˆ†æ
- ğŸ”„ å¼‚æ­¥æ”¯æŒï¼šæ”¯æŒå¼‚æ­¥å‡½æ•°æ—¥å¿—è®°å½•
- ğŸ“ è‡ªå®šä¹‰æ ¼å¼ï¼šæ”¯æŒè‡ªå®šä¹‰æ—¥å¿—æ ¼å¼
- ğŸ”’ å®‰å…¨æ€§ï¼šå†…ç½®é”™è¯¯å¤„ç†å’Œé…ç½®éªŒè¯
- ğŸ“¦ æ—¥å¿—è½®è½¬ï¼šæ”¯æŒæŒ‰å¤§å°å’Œæ—¶é—´è½®è½¬
- ğŸŒ è¿œç¨‹æ—¥å¿—ï¼šæ”¯æŒå¼‚æ­¥è¿œç¨‹æ—¥å¿—æ”¶é›†
- ğŸ› å¢å¼ºé”™è¯¯ä¿¡æ¯ï¼šæ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä½ç½®ã€è°ƒç”¨é“¾å’Œä»£ç è¡Œ
- âš¡ æ€§èƒ½ä¼˜åŒ–ï¼šæ™ºèƒ½ç¼“å­˜ã€è¿æ¥æ± ã€å†…å­˜ä¼˜åŒ–

## å®‰è£…

```bash
pip install xmi-logger
```

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from xmi_logger import XmiLogger

# åˆ›å»ºæ—¥å¿—è®°å½•å™¨å®ä¾‹
logger = XmiLogger(
    file_name="app",
    log_dir="logs",
    language="zh"  # ä½¿ç”¨ä¸­æ–‡è¾“å‡º
)

# è®°å½•ä¸åŒçº§åˆ«çš„æ—¥å¿—
logger.info("è¿™æ˜¯ä¸€æ¡ä¿¡æ¯æ—¥å¿—")
logger.warning("è¿™æ˜¯ä¸€æ¡è­¦å‘Šæ—¥å¿—")
logger.error("è¿™æ˜¯ä¸€æ¡é”™è¯¯æ—¥å¿—")
```

### å¼‚æ­¥å‡½æ•°æ”¯æŒ

```python
import asyncio

@logger.log_decorator()
async def async_function():
    await asyncio.sleep(1)
    return "å¼‚æ­¥æ“ä½œå®Œæˆ"

# ä½¿ç”¨å¼‚æ­¥å‡½æ•°
async def main():
    result = await async_function()
    logger.info(f"å¼‚æ­¥å‡½æ•°ç»“æœ: {result}")

asyncio.run(main())
```

### å¢å¼ºé”™è¯¯ä¿¡æ¯

```python
# é”™è¯¯æ—¥å¿—ç°åœ¨ä¼šæ˜¾ç¤ºè¯¦ç»†çš„ä½ç½®ä¿¡æ¯
@logger.log_decorator("é™¤é›¶é”™è¯¯", level="ERROR")
def divide_numbers(a, b):
    return a / b

try:
    result = divide_numbers(1, 0)
except ZeroDivisionError:
    logger.exception("æ•è·åˆ°é™¤é›¶é”™è¯¯")
    # è¾“å‡ºç¤ºä¾‹ï¼š
    # 2025-01-03 10:30:15.123 | ERROR    | ReqID:REQ-123 | app.py:25:divide_numbers | 12345 | é™¤é›¶é”™è¯¯ [ZeroDivisionError]: division by zero | ä½ç½®: app.py:25:divide_numbers | ä»£ç : return a / b
    # è°ƒç”¨é“¾: app.py:25:divide_numbers -> main.py:10:main
```

### å¸¦ä½ç½®ä¿¡æ¯çš„æ—¥å¿—

```python
# ä½¿ç”¨ log_with_location æ–¹æ³•è®°å½•å¸¦ä½ç½®ä¿¡æ¯çš„æ—¥å¿—
logger.log_with_location("INFO", "è¿™æ˜¯å¸¦ä½ç½®ä¿¡æ¯çš„æ—¥å¿—")
# è¾“å‡ºç¤ºä¾‹ï¼š
# 2025-01-03 10:30:15.123 | INFO     | ReqID:REQ-123 | app.py:30:main | 12345 | [app.py:30:main] è¿™æ˜¯å¸¦ä½ç½®ä¿¡æ¯çš„æ—¥å¿—
```

### æ€§èƒ½ç›‘æ§

```python
# è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
perf_stats = logger.get_performance_stats()
print(json.dumps(perf_stats, indent=2))

# æ¸…é™¤ç¼“å­˜
logger.clear_caches()

# æ€§èƒ½ä¼˜åŒ–é…ç½®
logger = XmiLogger(
    file_name="app",
    cache_size=512,        # å¢åŠ ç¼“å­˜å¤§å°
    enable_stats=True      # å¯ç”¨ç»Ÿè®¡åŠŸèƒ½
)
```

### æ‰¹é‡æ—¥å¿—å¤„ç†

```python
# æ‰¹é‡è®°å½•æ—¥å¿—
batch_logs = [
    {'level': 'INFO', 'message': 'æ¶ˆæ¯1', 'tag': 'BATCH'},
    {'level': 'WARNING', 'message': 'æ¶ˆæ¯2', 'category': 'SYSTEM'},
    {'level': 'ERROR', 'message': 'æ¶ˆæ¯3'}
]

logger.batch_log(batch_logs)  # åŒæ­¥æ‰¹é‡è®°å½•
logger.async_batch_log(batch_logs)  # å¼‚æ­¥æ‰¹é‡è®°å½•
```

### ä¸Šä¸‹æ–‡æ—¥å¿—

```python
# å¸¦ä¸Šä¸‹æ–‡çš„æ—¥å¿—è®°å½•
context = {
    'user_id': 12345,
    'session_id': 'sess_abc123',
    'request_id': 'req_xyz789'
}

logger.log_with_context("INFO", "ç”¨æˆ·ç™»å½•", context)
logger.log_with_timing("INFO", "APIè¯·æ±‚å®Œæˆ", {'db_query': 0.125, 'total': 0.467})
```

### è‡ªé€‚åº”æ—¥å¿—çº§åˆ«

```python
# å¯ç”¨è‡ªé€‚åº”çº§åˆ«
logger = XmiLogger(
    file_name="app",
    adaptive_level=True,    # å¯ç”¨è‡ªé€‚åº”çº§åˆ«
    performance_mode=True   # å¯ç”¨æ€§èƒ½æ¨¡å¼
)

# æ ¹æ®é”™è¯¯ç‡è‡ªåŠ¨è°ƒæ•´çº§åˆ«
logger.set_adaptive_level(error_rate_threshold=0.1)
```

### æ—¥å¿—ç®¡ç†

```python
# å‹ç¼©æ—§æ—¥å¿—
logger.compress_logs(days_old=7)

# å½’æ¡£æ—¥å¿—
logger.archive_logs()

# æ¸…ç†æ—§æ—¥å¿—
logger.cleanup_old_logs(max_days=30)
```

### æ—¥å¿—åˆ†æ

```python
# åˆ†ææ—¥å¿—
analysis = logger.analyze_logs(hours=24)
print(f"é”™è¯¯ç‡: {analysis['error_rate']:.2%}")

# ç”ŸæˆæŠ¥å‘Š
report = logger.generate_log_report(hours=24)
print(report)

# å¯¼å‡ºæ—¥å¿—
logger.export_logs_to_json("logs.json", hours=24)
```

### æ™ºèƒ½åˆ†æåŠŸèƒ½

```python
from xmi_logger.advanced_features import *

# æ™ºèƒ½æ—¥å¿—åˆ†æ
analyzer = LogAnalyzer()
analysis = analyzer.analyze_log({
    'message': 'æ•°æ®åº“è¿æ¥å¤±è´¥: Connection refused',
    'level': 'ERROR'
})
print(f"ä¸¥é‡ç¨‹åº¦: {analysis['severity']}")  # high
print(f"ç±»åˆ«: {analysis['categories']}")    # ['error']
print(f"å»ºè®®: {analysis['suggestions']}")   # ['æ£€æŸ¥ç›¸å…³æœåŠ¡å’Œä¾èµ–']

# åˆ†å¸ƒå¼æ—¥å¿—æ”¯æŒ
dist_logger = DistributedLogger("node-001")
log_id = dist_logger.get_log_id()  # node-001_1640995200000_1
logger.info(f"åˆ†å¸ƒå¼æ—¥å¿—æ¶ˆæ¯ (ID: {log_id})")

# æ—¥å¿—å®‰å…¨åŠŸèƒ½
security = LogSecurity()
original = "ç”¨æˆ·å¯†ç : 123456"
sanitized = security.sanitize_message(original)
print(sanitized)  # ç”¨æˆ·å¯†ç =***

# æ€§èƒ½ç›‘æ§
monitor = PerformanceMonitor()
monitor.record_log("INFO", 0.05)  # è®°å½•å¤„ç†æ—¶é—´
metrics = monitor.get_metrics()
print(f"æ€»æ—¥å¿—æ•°: {metrics['log_count']}")
print(f"å¹³å‡å¤„ç†æ—¶é—´: {metrics['avg_processing_time']:.2f}ms")

# æ—¥å¿—èšåˆ
aggregator = LogAggregator(window_size=100, flush_interval=5.0)
for i in range(20):
    aggregator.add_log({
        'level': 'INFO',
        'message': 'é‡å¤çš„æ—¥å¿—æ¶ˆæ¯',
        'timestamp': time.time()
    })
# è‡ªåŠ¨èšåˆä¸º: [èšåˆ] é‡å¤çš„æ—¥å¿—æ¶ˆæ¯ (é‡å¤ 20 æ¬¡)

# æµå¤„ç†
processor = LogStreamProcessor()

def add_timestamp(log_entry):
    log_entry['processed_timestamp'] = time.time()
    return log_entry

def add_checksum(log_entry):
    message = log_entry.get('message', '')
    log_entry['checksum'] = hashlib.md5(message.encode()).hexdigest()[:8]
    return log_entry

processor.add_processor(add_timestamp)
processor.add_processor(add_checksum)

# å¤„ç†æ—¥å¿—
processor.process_log({'level': 'INFO', 'message': 'æµ‹è¯•æ¶ˆæ¯'})
processed_log = processor.get_processed_log()

# æ•°æ®åº“æ”¯æŒ
db = LogDatabase("logs.db")
db.insert_log({
    'timestamp': datetime.now().isoformat(),
    'level': 'ERROR',
    'message': 'æ•°æ®åº“è¿æ¥å¤±è´¥',
    'file': 'app.py',
    'line': 100,
    'function': 'connect_db'
})

# æŸ¥è¯¢é”™è¯¯æ—¥å¿—
logs = db.query_logs({'level': 'ERROR'}, limit=10)

# å¥åº·æ£€æŸ¥
checker = LogHealthChecker()
health = checker.check_health("logs")
print(f"çŠ¶æ€: {health['status']}")  # healthy/warning/critical
print(f"ç£ç›˜ä½¿ç”¨ç‡: {health['disk_usage_percent']:.1f}%")

# å¤‡ä»½ç®¡ç†
backup_mgr = LogBackupManager("backups")
backup_path = backup_mgr.create_backup("logs", "daily_backup")

# åˆ—å‡ºå¤‡ä»½
backups = backup_mgr.list_backups()
for backup in backups:
    print(f"{backup['name']} - {backup['size_mb']:.2f}MB")

# å†…å­˜ä¼˜åŒ–
optimizer = MemoryOptimizer(max_memory_mb=512)
if optimizer.check_memory():
    optimizer.optimize_memory()  # è‡ªåŠ¨æ¸…ç†å†…å­˜

# æ™ºèƒ½è·¯ç”±
router = LogRouter()

def error_handler(log_entry):
    print(f"ğŸš¨ é”™è¯¯æ—¥å¿—: {log_entry['message']}")

def security_handler(log_entry):
    print(f"ğŸ”’ å®‰å…¨æ—¥å¿—: {log_entry['message']}")

router.add_route(lambda entry: entry.get('level') == 'ERROR', error_handler)
router.add_route(lambda entry: 'password' in entry.get('message', ''), security_handler)

router.route_log({'level': 'ERROR', 'message': 'ç³»ç»Ÿé”™è¯¯'})

# æ—¥å¿—å½’æ¡£
archiver = LogArchiver("archives")
archived_files = archiver.archive_logs("logs", days_old=7)
print(f"å½’æ¡£äº† {len(archived_files)} ä¸ªæ–‡ä»¶")
```

### è¿œç¨‹æ—¥å¿—æ”¶é›†

```python
logger = XmiLogger(
    file_name="app",
    remote_log_url="https://your-log-server.com/logs",
    max_workers=3
)
```

### æ—¥å¿—ç»Ÿè®¡åŠŸèƒ½

```python
# å¯ç”¨ç»Ÿè®¡åŠŸèƒ½
logger = XmiLogger(
    file_name="app",
    enable_stats=True
)

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = logger.get_stats()
print(logger.get_stats_summary())

# è·å–é”™è¯¯è¶‹åŠ¿
error_trend = logger.get_error_trend()

# è·å–åˆ†ç±»åˆ†å¸ƒ
category_dist = logger.get_category_distribution()
```

## é«˜çº§é…ç½®

### å®Œæ•´é…ç½®ç¤ºä¾‹

```python
logger = XmiLogger(
    file_name="app",                    # æ—¥å¿—æ–‡ä»¶å
    log_dir="logs",                     # æ—¥å¿—ç›®å½•
    max_size=14,                        # å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°ï¼ˆMBï¼‰
    retention="7 days",                 # æ—¥å¿—ä¿ç•™æ—¶é—´
    remote_log_url=None,                # è¿œç¨‹æ—¥å¿—æœåŠ¡å™¨URL
    max_workers=3,                      # è¿œç¨‹æ—¥å¿—å‘é€çº¿ç¨‹æ•°
    work_type=False,                    # å·¥ä½œæ¨¡å¼ï¼ˆFalseä¸ºæµ‹è¯•ç¯å¢ƒï¼‰
    language="zh",                      # æ—¥å¿—è¯­è¨€ï¼ˆzh/enï¼‰
    rotation_time="1 day",              # æ—¥å¿—è½®è½¬æ—¶é—´
    custom_format=None,                 # è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼
    filter_level="DEBUG",               # æ—¥å¿—è¿‡æ»¤çº§åˆ«
    compression="zip",                  # æ—¥å¿—å‹ç¼©æ ¼å¼
    enable_stats=False,                 # æ˜¯å¦å¯ç”¨ç»Ÿè®¡
    categories=None,                    # æ—¥å¿—åˆ†ç±»åˆ—è¡¨
    cache_size=128                      # ç¼“å­˜å¤§å°
)
```

### è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼

```python
custom_format = (
    "<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
    "<level>{level: <8}</level> | "
    "ReqID:{extra[request_id]} | "
    "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
    "<level>{message}</level>"
)

logger = XmiLogger(
    file_name="app",
    custom_format=custom_format
)
```

## ä¸»è¦åŠŸèƒ½

### 1. æ—¥å¿—è®°å½•
- æ”¯æŒæ‰€æœ‰æ ‡å‡†æ—¥å¿—çº§åˆ«ï¼ˆDEBUG, INFO, WARNING, ERROR, CRITICALï¼‰
- æ”¯æŒè‡ªå®šä¹‰æ—¥å¿—çº§åˆ«
- æ”¯æŒå¸¦æ ‡ç­¾å’Œåˆ†ç±»çš„æ—¥å¿—è®°å½•

### 2. æ—¥å¿—ç®¡ç†
- è‡ªåŠ¨æ—¥å¿—è½®è½¬
- æ—¥å¿—å‹ç¼©
- æ—¥å¿—ä¿ç•™ç­–ç•¥
- å¤šæ–‡ä»¶è¾“å‡ºï¼ˆæŒ‰çº§åˆ«åˆ†æ–‡ä»¶ï¼‰

### 3. ç»Ÿè®¡åŠŸèƒ½
- æ—¥å¿—æ€»æ•°ç»Ÿè®¡
- é”™è¯¯ç‡ç»Ÿè®¡
- æŒ‰ç±»åˆ«ç»Ÿè®¡
- æŒ‰æ—¶é—´ç»Ÿè®¡
- é”™è¯¯è¶‹åŠ¿åˆ†æ

### 4. è¿œç¨‹æ—¥å¿—
- å¼‚æ­¥è¿œç¨‹æ—¥å¿—å‘é€
- è‡ªåŠ¨é‡è¯•æœºåˆ¶
- çº¿ç¨‹æ± ç®¡ç†
- é”™è¯¯å¤„ç†

### 5. è£…é¥°å™¨æ”¯æŒ
- å‡½æ•°æ‰§è¡Œæ—¶é—´è®°å½•
- å¼‚å¸¸æ•è·å’Œè®°å½•
- æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥å‡½æ•°

### 6. å¢å¼ºé”™è¯¯ä¿¡æ¯
- æ˜¾ç¤ºé”™è¯¯å‘ç”Ÿçš„å…·ä½“æ–‡ä»¶ã€è¡Œå·å’Œå‡½æ•°å
- æ˜¾ç¤ºé”™è¯¯å‘ç”Ÿæ—¶çš„ä»£ç è¡Œå†…å®¹
- æ˜¾ç¤ºè°ƒç”¨é“¾ä¿¡æ¯ï¼ˆæœ€å3å±‚è°ƒç”¨ï¼‰
- æ”¯æŒå…¨å±€å¼‚å¸¸å¤„ç†å™¨
- æä¾›å¸¦ä½ç½®ä¿¡æ¯çš„æ—¥å¿—è®°å½•æ–¹æ³•

### 7. æ€§èƒ½ä¼˜åŒ–
- æ™ºèƒ½ç¼“å­˜æœºåˆ¶å‡å°‘é‡å¤è®¡ç®—
- è¿æ¥æ± ä¼˜åŒ–ç½‘ç»œè¯·æ±‚æ€§èƒ½
- å†…å­˜ä¼˜åŒ–å‡å°‘å¯¹è±¡åˆ›å»º
- ç»Ÿè®¡ç¼“å­˜æé«˜æŸ¥è¯¢æ•ˆç‡
- çº¿ç¨‹æœ¬åœ°ç¼“å­˜æå‡å¹¶å‘æ€§èƒ½

### 8. é«˜çº§åŠŸèƒ½
- æ‰¹é‡æ—¥å¿—å¤„ç†æé«˜å¤§é‡æ—¥å¿—è®°å½•æ€§èƒ½
- ä¸Šä¸‹æ–‡æ—¥å¿—è‡ªåŠ¨æ·»åŠ ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯
- è‡ªé€‚åº”çº§åˆ«æ ¹æ®ç³»ç»ŸçŠ¶æ€è‡ªåŠ¨è°ƒæ•´æ—¥å¿—çº§åˆ«
- æ—¥å¿—ç®¡ç†å‹ç¼©ã€å½’æ¡£ã€æ¸…ç†åŠŸèƒ½
- æ—¥å¿—åˆ†ææ™ºèƒ½åˆ†ææ—¥å¿—å†…å®¹å’Œè¶‹åŠ¿
- æ€§èƒ½ç›‘æ§å®æ—¶ç›‘æ§ç¼“å­˜å’Œæ€§èƒ½æŒ‡æ ‡

### 9. æ™ºèƒ½åˆ†æåŠŸèƒ½
- æ™ºèƒ½æ—¥å¿—åˆ†æè‡ªåŠ¨è¯†åˆ«é”™è¯¯ã€è­¦å‘Šã€å®‰å…¨äº‹ä»¶
- åˆ†å¸ƒå¼æ—¥å¿—æ”¯æŒå¤šèŠ‚ç‚¹ç¯å¢ƒï¼Œæä¾›å”¯ä¸€æ—¥å¿—ID
- æ—¥å¿—å®‰å…¨åŠŸèƒ½æ•æ„Ÿä¿¡æ¯æ¸…ç†å’ŒåŠ å¯†
- æ€§èƒ½ç›‘æ§å®æ—¶ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨
- æ—¥å¿—èšåˆè‡ªåŠ¨èšåˆé‡å¤æ—¥å¿—
- æµå¤„ç†å¯æ‰©å±•çš„æ—¥å¿—å¤„ç†ç®¡é“
- æ•°æ®åº“æ”¯æŒç»“æ„åŒ–æ—¥å¿—å­˜å‚¨å’ŒæŸ¥è¯¢
- å¥åº·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€ç›‘æ§
- å¤‡ä»½ç®¡ç†è‡ªåŠ¨å¤‡ä»½å’Œæ¢å¤
- å†…å­˜ä¼˜åŒ–æ™ºèƒ½åƒåœ¾å›æ”¶
- æ™ºèƒ½è·¯ç”±åŸºäºæ¡ä»¶çš„æ—¥å¿—åˆ†å‘
- æ—¥å¿—å½’æ¡£è‡ªåŠ¨å‹ç¼©å’Œå½’æ¡£

## é”™è¯¯å¤„ç†

```python
try:
    logger = XmiLogger("app", log_dir="/path/to/logs")
except RuntimeError as e:
    print(f"æ—¥å¿—é…ç½®å¤±è´¥: {e}")
```

## æ³¨æ„äº‹é¡¹

1. ç¡®ä¿æ—¥å¿—ç›®å½•å…·æœ‰å†™å…¥æƒé™
2. è¿œç¨‹æ—¥å¿—URLå¿…é¡»æ˜¯æœ‰æ•ˆçš„HTTP(S)åœ°å€
3. å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨ç»Ÿè®¡åŠŸèƒ½
4. å¼‚æ­¥æ“ä½œæ—¶æ³¨æ„æ­£ç¡®å¤„ç†å¼‚å¸¸

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯

MIT License

